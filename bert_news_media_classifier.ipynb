{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_news_media_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X4dlNPc0fTMt",
        "outputId": "82cdcce0-cf26-454d-e80d-a4cdae135511"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfiJrn_hfusN"
      },
      "source": [
        "if os.getcwd() != '/content/drive/MyDrive/ml_datasets/data':\n",
        "    os.chdir('/content/drive/MyDrive/ml_datasets/data')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNE3OaPof703"
      },
      "source": [
        "VIOLENT_FILE = os.path.join(os.getcwd(), 'violent_train.txt')\n",
        "NOT_VIOLENT_FILE = os.path.join(os.getcwd(), 'not_violent_train.txt')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89LYqLjLf_1F"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import re\n",
        "import random\n",
        "import unicodedata\n",
        "import codecs\n",
        "import itertools\n",
        "import operator\n",
        "from io import open\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "class NewsMediaDataset(Dataset):\n",
        "    def __init__(self, v_filename=VIOLENT_FILE, nv_filename=NOT_VIOLENT_FILE, min_length=10):\n",
        "        self.min_length = min_length\n",
        "        self.v_articles = self.read_utterances(filename=v_filename)\n",
        "        self.nv_articles = self.read_utterances(filename=nv_filename)\n",
        "        self.classes = {\"violent\": 1, \"not_violent\": 0}\n",
        "        self.n_samples = len(self.v_articles) + len(self.nv_articles)\n",
        "        v_inputs = self.input_generator(self.v_articles)\n",
        "        nv_inputs = self.input_generator(self.nv_articles)\n",
        "        self.inputs = v_inputs + nv_inputs\n",
        "        random.shuffle(self.inputs)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        article = self.inputs[index][0]\n",
        "        target = self.inputs[index][1]\n",
        "        return article, target\n",
        "    \n",
        "    def unicodeToAscii(self, s):\n",
        "        return ''.join(\n",
        "            c for c in unicodedata.normalize('NFD', s)\n",
        "            if unicodedata.category(c) != 'Mn'\n",
        "        )\n",
        "\n",
        "    def normalizeString(self, s):\n",
        "        s = self.unicodeToAscii(s.lower().strip())\n",
        "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "        s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "        return s\n",
        "\n",
        "    def read_utterances(self, filename):\n",
        "        lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "        articles = [self.normalizeString(l) for l in lines]\n",
        "        return articles\n",
        "\n",
        "    def input_generator(self, articles):\n",
        "        inputs = []\n",
        "        for article in articles:\n",
        "            if article in self.v_articles:\n",
        "                target = self.classes[\"violent\"]\n",
        "            elif article in self.nv_articles:\n",
        "                target = self.classes[\"not_violent\"]\n",
        "            inputs.append([article, target])\n",
        "        return inputs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIQOYVxpgbph",
        "outputId": "d97be70f-c0f1-4e4f-910e-3404b5d6a7d8"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"device = \", device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device =  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2joHWIygz1F",
        "outputId": "f57b5736-5639-470a-b84a-66e37f28274b"
      },
      "source": [
        "mediaDataset = NewsMediaDataset()\n",
        "print('Dataset length : ', len(mediaDataset))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset length :  6244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3kaqQc1g6nq"
      },
      "source": [
        "sentences, targets = [], []\n",
        "\n",
        "for item in mediaDataset:\n",
        "    sentences.append(item[0])\n",
        "    targets.append(item[1])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etsT-LYphRlL",
        "outputId": "38be21e7-4789-434f-a7be-333faea7d2d0"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clCB2_ZNhZPc",
        "outputId": "880bc6f7-9096-4e31-8d82-b9cf11252692"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpti2PgmhsoT",
        "outputId": "36821047-0b2d-4661-8e36-54dc15339e4d"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    \n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True, \n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (767 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  april a mosque in gorakhpur s bankata village was vandalised and the muezzin was attacked by goons for allegedly giving azaan on a loudspeaker amid lockdown . according to hindustan times reports the incident took place on sunday afternoon under sikriganj police station limit of the district . the trouble begin when the year old muezzin abdul rahman gave the azaan . as soon as the muezzin concluded the call to prayer five to six people barged into the mosque and created ruckus . the attackers thrashed the muezzin and also allegedly desecrated the holy quran and also broke the sound box of the loudspeaker . ali said after hearing the commotion he locked the attackers by closing the door and informed police . in the meantime the attackers came out of the mosque an began abusing and threaten him with dire consequences and went away . later on they came with some more men and attacked ali . when his father azmat ali rushed to his help the goons also beaten azmat who suffered severe head injuries and fracture . the attackers then fled the scene . this led to communal tension in the locality . upon getting the information police rushed to site and appeal to maintain harmony . people from both the sides are ready for a compromise and have assured us that such incident will not reoccur said jatashankar station house officer sikriganj police station .\n",
            "Token IDs: [101, 2258, 1037, 8806, 1999, 26967, 10023, 5311, 1055, 2924, 6790, 2352, 2001, 3158, 9305, 5084, 1998, 1996, 14163, 9351, 17168, 2001, 4457, 2011, 27571, 3619, 2005, 9382, 3228, 17207, 14634, 2006, 1037, 5189, 13102, 25508, 2121, 13463, 5843, 7698, 1012, 2429, 2000, 18221, 5794, 2335, 4311, 1996, 5043, 2165, 2173, 2006, 4465, 5027, 2104, 9033, 21638, 10762, 3501, 2610, 2276, 5787, 1997, 1996, 2212, 1012, 1996, 4390, 4088, 2043, 1996, 2095, 2214, 14163, 9351, 17168, 10298, 14364, 2435, 1996, 17207, 14634, 1012, 2004, 2574, 2004, 1996, 14163, 9351, 17168, 5531, 1996, 2655, 2000, 7083, 2274, 2000, 2416, 2111, 19398, 2094, 2046, 1996, 8806, 1998, 2580, 21766, 3600, 2271, 1012, 1996, 17857, 27042, 2098, 1996, 14163, 9351, 17168, 1998, 2036, 9382, 4078, 8586, 9250, 1996, 4151, 21288, 1998, 2036, 3631, 1996, 2614, 3482, 1997, 1996, 5189, 13102, 25508, 2121, 1012, 4862, 2056, 2044, 4994, 1996, 23960, 2002, 5299, 1996, 17857, 2011, 5494, 1996, 2341, 1998, 6727, 2610, 1012, 1999, 1996, 12507, 1996, 17857, 2234, 2041, 1997, 1996, 8806, 2019, 2211, 8273, 7741, 1998, 15686, 2032, 2007, 18704, 8465, 1998, 2253, 2185, 1012, 2101, 2006, 2027, 2234, 2007, 2070, 2062, 2273, 1998, 4457, 4862, 1012, 2043, 2010, 2269, 17207, 18900, 4862, 6760, 2000, 2010, 2393, 1996, 27571, 3619, 2036, 7854, 17207, 18900, 2040, 4265, 5729, 2132, 6441, 1998, 19583, 1012, 1996, 17857, 2059, 6783, 1996, 3496, 1012, 2023, 2419, 2000, 15029, 6980, 1999, 1996, 10246, 1012, 2588, 2893, 1996, 2592, 2610, 6760, 2000, 2609, 1998, 5574, 2000, 5441, 9396, 1012, 2111, 2013, 2119, 1996, 3903, 2024, 3201, 2005, 1037, 12014, 1998, 2031, 8916, 2149, 2008, 2107, 5043, 2097, 2025, 2128, 10085, 10841, 2099, 2056, 14855, 10230, 4819, 6673, 2276, 2160, 2961, 9033, 21638, 10762, 3501, 2610, 2276, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2nGomqrh68n",
        "outputId": "2d040669-2f93-40e9-a586-74c392772d44"
      },
      "source": [
        "MAX_LEN = 512\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 512 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEBfRXXpijEi"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U50MqY5si254"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, targets, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, targets,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd4NbEC0nHvb"
      },
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKz-dbGUjFgz"
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJVwjy30jMv2"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "batch_size = 8 # 16\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FppKmAgVje9H",
        "outputId": "87c9983f-e672-46b3-f5a6-75ef2826c487"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", \n",
        "    num_labels = 2, \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False, \n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3uLbheQj78T"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag-UWWXilMMa"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GaBsrHvldFJ"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6yLYfHhlk1e"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdztGxunq01M",
        "outputId": "a0b3bd49-f498-4418-bc80-d4030f82153e"
      },
      "source": [
        "device"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y6tJIaZlpm_",
        "outputId": "5ad271d8-70bd-43e9-e618-e9454b478f72"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    \n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        \n",
        "        model.zero_grad()        \n",
        "\n",
        "        \n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "    \n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "    \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    \n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        \n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        \n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            \n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        \n",
        "        logits = outputs[0]\n",
        "\n",
        "        \n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        \n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        \n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    \n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    703.    Elapsed: 0:00:57.\n",
            "  Batch    80  of    703.    Elapsed: 0:01:56.\n",
            "  Batch   120  of    703.    Elapsed: 0:02:54.\n",
            "  Batch   160  of    703.    Elapsed: 0:03:52.\n",
            "  Batch   200  of    703.    Elapsed: 0:04:50.\n",
            "  Batch   240  of    703.    Elapsed: 0:05:49.\n",
            "  Batch   280  of    703.    Elapsed: 0:06:47.\n",
            "  Batch   320  of    703.    Elapsed: 0:07:45.\n",
            "  Batch   360  of    703.    Elapsed: 0:08:43.\n",
            "  Batch   400  of    703.    Elapsed: 0:09:41.\n",
            "  Batch   440  of    703.    Elapsed: 0:10:39.\n",
            "  Batch   480  of    703.    Elapsed: 0:11:37.\n",
            "  Batch   520  of    703.    Elapsed: 0:12:35.\n",
            "  Batch   560  of    703.    Elapsed: 0:13:33.\n",
            "  Batch   600  of    703.    Elapsed: 0:14:32.\n",
            "  Batch   640  of    703.    Elapsed: 0:15:30.\n",
            "  Batch   680  of    703.    Elapsed: 0:16:28.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:17:01\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation took: 0:00:40\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    703.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    703.    Elapsed: 0:01:58.\n",
            "  Batch   120  of    703.    Elapsed: 0:02:57.\n",
            "  Batch   160  of    703.    Elapsed: 0:03:55.\n",
            "  Batch   200  of    703.    Elapsed: 0:04:54.\n",
            "  Batch   240  of    703.    Elapsed: 0:05:52.\n",
            "  Batch   280  of    703.    Elapsed: 0:06:51.\n",
            "  Batch   320  of    703.    Elapsed: 0:07:50.\n",
            "  Batch   360  of    703.    Elapsed: 0:08:49.\n",
            "  Batch   400  of    703.    Elapsed: 0:09:47.\n",
            "  Batch   440  of    703.    Elapsed: 0:10:46.\n",
            "  Batch   480  of    703.    Elapsed: 0:11:44.\n",
            "  Batch   520  of    703.    Elapsed: 0:12:43.\n",
            "  Batch   560  of    703.    Elapsed: 0:13:42.\n",
            "  Batch   600  of    703.    Elapsed: 0:14:40.\n",
            "  Batch   640  of    703.    Elapsed: 0:15:39.\n",
            "  Batch   680  of    703.    Elapsed: 0:16:38.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:17:11\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.99\n",
            "  Validation took: 0:00:40\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjeVUsxamDHX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "779bc7e7-1ad8-4d7d-fb49-5736106e75c3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF4a11kX5r6B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}