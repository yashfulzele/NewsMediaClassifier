{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from sacremoses import MosesTokenizer\n",
    "import re\n",
    "import random\n",
    "import unicodedata\n",
    "import codecs\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import operator\n",
    "from io import open\n",
    "import math\n",
    "import numpy as np\n",
    "from ipywidgets import IntProgress\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "mt = MosesTokenizer(lang='en')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device =  cuda\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(\"device = \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIOLENT_FILE = os.path.join(os.getcwd(), 'data/violent_train.txt')\n",
    "NOT_VIOLENT_FILE = os.path.join(os.getcwd(), 'data/not_violent_train.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, name, freq_threshold=5):\n",
    "        self.name = name\n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.word2index = {\"<PAD>\":PAD_token, \"<SOS>\":SOS_token, \"<EOS>\":EOS_token, \"<UNK>\":UNK_token}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token:\"<PAD>\", SOS_token:\"<SOS>\", EOS_token:\"<EOS>\", UNK_token:\"<UNK>\"}\n",
    "        self.n_words = 4\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index2word)\n",
    "\n",
    "    def remove_non_ascii(self, words):\n",
    "        \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "            new_words.append(new_word)\n",
    "        return new_words\n",
    "\n",
    "    def to_lowercase(self, words):\n",
    "        \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = word.lower()\n",
    "            new_words.append(new_word)\n",
    "        return new_words\n",
    "\n",
    "    def remove_punctuation(self, words):\n",
    "        \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "        return new_words\n",
    "\n",
    "    def normalize(self, words):\n",
    "        words = self.remove_non_ascii(words)\n",
    "        words = self.to_lowercase(words)\n",
    "        words = self.remove_punctuation(words)\n",
    "        return words\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        words = []\n",
    "        for word in mt.tokenize(sentence):\n",
    "            words.append(word)\n",
    "        words = self.normalize(words)\n",
    "        for word in words:\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2count:\n",
    "            self.word2count[word] = 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "        if self.word2count[word] == self.freq_threshold:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "    \n",
    "    def addWord_trimmed(self, word):\n",
    "        self.word2index[word] = self.n_words\n",
    "        self.index2word[self.n_words] = word\n",
    "        self.n_words += 1\n",
    "    \n",
    "    def trimWords(self, MAX_VOCAB_SIZE=30000):\n",
    "        self.word2count=dict(sorted(self.word2count.items(), key=operator.itemgetter(1), reverse=True))\n",
    "        iter = 0\n",
    "        keep_words = []\n",
    "        for key in self.word2count:\n",
    "            keep_words.append(key)\n",
    "            iter += 1\n",
    "            if iter == MAX_VOCAB_SIZE:\n",
    "                break\n",
    "        self.word2index = {\"<PAD>\":PAD_token, \"<SOS>\":SOS_token, \"<EOS>\":EOS_token, \"<UNK>\":UNK_token}\n",
    "        self.index2word = {PAD_token:\"<PAD>\", SOS_token:\"<SOS>\", EOS_token:\"<EOS>\", UNK_token:\"<UNK>\"}\n",
    "        self.n_words = 4\n",
    "        for word in keep_words:\n",
    "            self.addWord_trimmed(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsMediaDataset(Dataset):\n",
    "    def __init__(self, v_filename=VIOLENT_FILE, nv_filename=NOT_VIOLENT_FILE, min_length=10):\n",
    "        self.min_length = min_length\n",
    "        self.v_articles = self.read_utterances(filename=v_filename)\n",
    "        self.nv_articles = self.read_utterances(filename=nv_filename)\n",
    "        self.classes = {\"violent\": 1, \"not_violent\": 0}\n",
    "        self.n_samples = len(self.v_articles) + len(self.nv_articles)\n",
    "        v_inputs = self.input_generator(self.v_articles)\n",
    "        nv_inputs = self.input_generator(self.nv_articles)\n",
    "        self.inputs = v_inputs + nv_inputs\n",
    "        random.shuffle(self.inputs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        article = self.inputs[index][0]\n",
    "        target = self.inputs[index][1]\n",
    "        return article, target\n",
    "    \n",
    "    def unicodeToAscii(self, s):\n",
    "        return ''.join(\n",
    "            c for c in unicodedata.normalize('NFD', s)\n",
    "            if unicodedata.category(c) != 'Mn'\n",
    "        )\n",
    "\n",
    "    def normalizeString(self, s):\n",
    "        s = self.unicodeToAscii(s.lower().strip())\n",
    "        s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "        s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "        s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "        return s\n",
    "\n",
    "    def read_utterances(self, filename):\n",
    "        lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "        articles = [self.normalizeString(l) for l in lines]\n",
    "        return articles\n",
    "\n",
    "    def input_generator(self, articles):\n",
    "        inputs = []\n",
    "        for article in articles:\n",
    "            if article in self.v_articles:\n",
    "                target = self.classes[\"violent\"]\n",
    "            elif article in self.nv_articles:\n",
    "                target = self.classes[\"not_violent\"]\n",
    "            inputs.append([article, target])\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset length :  6244\n",
      "Vocab length :  13301\n"
     ]
    }
   ],
   "source": [
    "mediaDataset = NewsMediaDataset()\n",
    "print('Dataset length : ', len(mediaDataset))\n",
    "\n",
    "vocab = Vocab('news_media')\n",
    "for input in mediaDataset:\n",
    "    sent = input[0]\n",
    "    vocab.addSentence(sent)\n",
    "\n",
    "print('Vocab length : ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(vocab, sentence):\n",
    "    tokens = []\n",
    "    for word in mt.tokenize(sentence):\n",
    "        if word in vocab.word2index:\n",
    "            tokens.append(vocab.word2index[word])\n",
    "        else:\n",
    "            tokens.append(vocab.word2index['<UNK>'])\n",
    "    tokens.append(EOS_token)\n",
    "    return tokens\n",
    "\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def inputVar(l, vocab):\n",
    "    indexes_batch = [indexesFromSentence(vocab, sentence) for sentence in l]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "def batch2TrainData(vocab, input_batches):\n",
    "    input_batches.sort(key=lambda x: len(mt.tokenize(x[0])), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for inp in input_batches:\n",
    "        input_batch.append(inp[0])\n",
    "        output_batch.append(inp[1])\n",
    "    inp, lengths = inputVar(input_batch, vocab)\n",
    "    output_batch = torch.tensor(output_batch)\n",
    "    return inp, lengths, output_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n\n\ninput_variable: tensor([[  34,  253,  953,    4,  149],\n        [ 903,  271, 1359,  393,  480],\n        [  88,   24,    8,   23, 1388],\n        ...,\n        [  77,    0,    0,    0,    0],\n        [   3,    0,    0,    0,    0],\n        [   2,    0,    0,    0,    0]])\nlengths: tensor([727, 642, 415, 217,  32])\ntarget_variable: tensor([0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "small_batch_size = 5\n",
    "batches = batch2TrainData(vocab, [random.choice(mediaDataset) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, outputs = batches\n",
    "print(\"\\n\\n\")\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers=1, dropout=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size,\n",
    "                          n_layers, dropout=(0 if n_layers == 1 else dropout),\n",
    "                          batch_first=False, bidirectional=True)\n",
    "        self.decoder = nn.Linear(hidden_size * 2, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_seq, input_lengths, hidden=None):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        output_ = self.decoder(hidden)\n",
    "        return self.act(output_.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 8\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.5\n",
    "\n",
    "embedding = nn.Embedding(vocab.n_words, HIDDEN_SIZE)\n",
    "\n",
    "model = EncoderRNN(hidden_size=HIDDEN_SIZE, \n",
    "                   embedding=embedding, \n",
    "                   n_layers=N_LAYERS, \n",
    "                   dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model has 1,900,929 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "EncoderRNN(\n  (embedding): Embedding(13301, 128)\n  (gru): GRU(128, 128, bidirectional=True)\n  (decoder): Linear(in_features=256, out_features=1, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n  (act): Sigmoid()\n)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, vocab, optimizer, criterion, batch_size, n_iters, device, clip):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    batches = [batch2TrainData(vocab, \n",
    "               [random.choice(train_dataset) \n",
    "               for _ in range(batch_size)])\n",
    "               for _ in range(n_iters)]\n",
    "    \n",
    "    for batch in batches:\n",
    "\n",
    "        inputs, lengths, outputs = batch\n",
    "        inputs, lengths, outputs = inputs.to(device), lengths.to(device), outputs.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(inputs, lengths)\n",
    "\n",
    "        outputs = outputs.type_as(predictions)\n",
    "\n",
    "        loss = criterion(predictions, outputs)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, outputs)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(batches), epoch_acc / len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset, vocab, criterion, batch_size, n_iters, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        batches = [batch2TrainData(vocab, \n",
    "                   [random.choice(test_dataset) \n",
    "                   for _ in range(batch_size)])\n",
    "                   for _ in range(n_iters)]\n",
    "    \n",
    "        for batch in batches:\n",
    "\n",
    "            inputs, lengths, outputs = batch\n",
    "            inputs, lengths, outputs = inputs.to(device), lengths.to(device), outputs.to(device)\n",
    "\n",
    "            predictions = model(inputs, lengths)\n",
    "\n",
    "            outputs = outputs.type_as(predictions)\n",
    "            \n",
    "            loss = criterion(predictions, outputs)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, outputs)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(batches), epoch_acc / len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "N_ITERS = 100\n",
    "N_SPLITS = 5\n",
    "CLIP = 3\n",
    "\n",
    "folds = KFold(n_splits=N_SPLITS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c72644af8c584bb29f39cf75eb52e2ec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-78f1a4479d74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                                       \u001b[0mn_iters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mN_ITERS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                                       \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                                       clip=CLIP)\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         valid_loss, valid_acc = evaluate(model=model,\n",
      "\u001b[1;32m<ipython-input-15-8f21cef13f13>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataset, vocab, optimizer, criterion, batch_size, n_iters, device, clip)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for train_index, test_index in folds.split(mediaDataset):\n",
    "\n",
    "    train_dataset, test_dataset = [], []\n",
    "\n",
    "    for tr_idx in train_index:\n",
    "        train_dataset.append(mediaDataset[tr_idx])\n",
    "\n",
    "    for te_idx in test_index:\n",
    "        test_dataset.append(mediaDataset[te_idx])\n",
    "    \n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in tqdm(range(N_EPOCHS)):\n",
    "\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss, train_acc = train(model=model,\n",
    "                                      train_dataset=train_dataset, \n",
    "                                      vocab=vocab,\n",
    "                                      optimizer=optimizer, \n",
    "                                      criterion=criterion,\n",
    "                                      batch_size=BATCH_SIZE,\n",
    "                                      n_iters=N_ITERS,\n",
    "                                      device=device,\n",
    "                                      clip=CLIP)\n",
    "\n",
    "        valid_loss, valid_acc = evaluate(model=model,\n",
    "                                         test_dataset=test_dataset, \n",
    "                                         vocab=vocab, \n",
    "                                         criterion=criterion,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         n_iters=N_ITERS,\n",
    "                                         device=device)\n",
    "        \n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "        \n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}